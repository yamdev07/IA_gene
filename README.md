# ğŸ“˜ Fineâ€‘Tuning dâ€™un ModÃ¨le GÃ©nÃ©ratif sur des Logs SystÃ¨me

## ğŸ§  PrÃ©sentation du Projet

Ce projet a pour objectif de fineâ€‘tuner un petit modÃ¨le gÃ©nÃ©ratif (GPTâ€‘2, DistilGPTâ€‘2 ou LLaMAâ€‘tiny) afin de gÃ©nÃ©rer automatiquement des **lignes de logs systÃ¨me rÃ©alistes**.  

Le projet permet de :

- Comprendre le principe du fineâ€‘tuning dâ€™un modÃ¨le de langage.
- PrÃ©parer un jeu de donnÃ©es de logs pour lâ€™apprentissage supervisÃ©.
- EntraÃ®ner un petit modÃ¨le gÃ©nÃ©ratif sur ces donnÃ©es.
- Ã‰valuer la qualitÃ© et la cohÃ©rence des logs gÃ©nÃ©rÃ©s.
- Identifier les enjeux de sÃ©curitÃ© liÃ©s aux donnÃ©es sensibles.

### Contexte

Les administrateurs systÃ¨me collectent de grands volumes de logs (SSH, Apache, Windows, etc.) pour dÃ©tecter des comportements anormaux.  
Les modÃ¨les gÃ©nÃ©ratifs peuvent Ãªtre utilisÃ©s pour :

- Simuler des journaux rÃ©alistes pour tester un SIEM.
- ComplÃ©ter des datasets pour entraÃ®ner des systÃ¨mes de dÃ©tection dâ€™anomalies.
- Identifier des patterns rares ou suspects.

---

## ğŸ“‚ Structure du Projet

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ logs_raw.txt # DonnÃ©es brutes
â”‚ â””â”€â”€ logs_clean.txt # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ model_logs/ # Checkpoints (Ã  ignorer dans Git)
â”œâ”€â”€ train.py # Script de fine-tuning
â”œâ”€â”€ generate.py # Script pour gÃ©nÃ©rer des logs
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â””â”€â”€ README.md # Documentation


---

## âš™ï¸ PrÃ©requis

- Python 3.10+
- pip
- GPU recommandÃ© (CUDA pour accÃ©lÃ©rer lâ€™entraÃ®nement)

Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```


# ğŸ“˜ PrÃ©paration des DonnÃ©es

- Nettoyer les logs (supprimer timestamps inutiles, caractÃ¨res spÃ©ciaux, lignes vides)
- HomogÃ©nÃ©iser le format (une ligne = un log)
- Anonymiser les donnÃ©es sensibles (IP internes, identifiants, etc.)

Exemple de log formatÃ© :

Jan 12 08:42:10 server sshd[2140]: Failed password for root from 192.168.1.24 port 52214 ssh2


---

# ğŸ‹ï¸â€â™‚ï¸ EntraÃ®nement du ModÃ¨le

```bash
python train.py \
  --model_name distilgpt2 \
  --dataset_path data/logs_clean.txt \
  --output_dir model_logs/
```

Les checkpoints seront sauvegardÃ©s dans model_logs/.

# ğŸ§ª GÃ©nÃ©ration de Logs

```bash
python generate.py \
  --model_dir model_logs/checkpoint-XX \
  --num_lines 20
````
# ğŸ“Š Ã‰valuation

- **Pertinence syntaxique** : Les logs gÃ©nÃ©rÃ©s ressemblent-ils Ã  de vrais logs ?
- **CohÃ©rence** : Structure correcte (timestamp, service, PID, action, IPâ€¦)
- **DiversitÃ©** : Le modÃ¨le ne rÃ©pÃ¨te pas les mÃªmes lignes
- **SÃ©curitÃ©** : Pas de fuite de donnÃ©es sensibles, pas de reproduction exacte de logs critiques

---

# ğŸ” SÃ©curitÃ© & Ã‰thique

- Toujours anonymiser les donnÃ©es avant entraÃ®nement.
- Ne pas publier de logs rÃ©els non anonymisÃ©s.
- Utiliser le modÃ¨le uniquement pour testing et recherche.

---

# ğŸš€ Objectifs PÃ©dagogiques

- Comprendre le fine-tuning dâ€™un modÃ¨le gÃ©nÃ©ratif.
- PrÃ©parer un dataset spÃ©cialisÃ© pour lâ€™entraÃ®nement.
- Fine-tuner un petit LLM pour gÃ©nÃ©rer des logs.
- Ã‰valuer la qualitÃ© des gÃ©nÃ©rations.
- Identifier les risques liÃ©s aux donnÃ©es sensibles.

---

# ğŸ¤ Auteur

Projet rÃ©alisÃ© par **yamdev07**  
Dans le cadre du **TP Chapitre 1 â€“ IA GÃ©nÃ©rative & SÃ©curitÃ© SystÃ¨mes**.
